{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "import sklearn.preprocessing as skp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates Lagged series\n",
    "#Goes through a series and generates an lag+1 dimensional pandas DataFrame that has each previous lag timeunit\n",
    "#as a column and current as the last cobilumn\n",
    "#Input: Pandas Series\n",
    "#Output: lag+1 dimensional DataFrame\n",
    "\n",
    "def timeseriesLagged(data, lag=60):\n",
    "    df = data\n",
    "    columns = [df.shift(i) for i in range(1, lag+2)] \n",
    "    df = pd.concat(columns,axis=1)\n",
    "    df.fillna(0, inplace=True)\n",
    "    df.columns = [str(lag+2-x) for x in range(1,lag+2)]\n",
    "    # df.reset_index(inplace=True,drop=False)\n",
    "    df = df[df.columns[::-1]] #Flip because we want newer data on the right\n",
    "    df= df.iloc[lag+1:] # drop the first 'lag' columns because zeroes.\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    return df\n",
    "\n",
    "# Binarizes the last column into 1, 0, -1. 1 = buy 0 = do nothing -1 = sell\n",
    "# Rate is the percent increase or decrease that should trigger a buy or a sell\n",
    "# lag is the time unit of lag. \n",
    "# atleast is how many of the lookahead need to be atleast the same or greater than flat+rat\n",
    "# Input: lagged pandas DataFrame, uint lag, double dif, double flat, double atleast between 0 and 1\n",
    "# Output : Pandas Dataframe with last column binarized\n",
    "def binarizeTime(resLagged,rate = 0,lookahead = 0, flat = 0,atleast = 0.5):\n",
    "    if lookahead <= 0 :\n",
    "        raise Exception(\"lookahead Must be 1 or higher!\")\n",
    "    resLagged = resLagged.copy() # Make a deep copy\n",
    "    last = np.shape(resLagged)[1] # find the length of the data \n",
    "    last = last-lookahead # convert it to string for loc\n",
    "    colsLookAhead = list(resLagged.loc[:,str(last+1):str(last + lookahead)])\n",
    "    colsLast = resLagged[str(last)]\n",
    "    diffs = resLagged[colsLookAhead].subtract(colsLast,axis=0)\n",
    "#     print(diffs)\n",
    "    greater = diffs>=flat  # all the times the price changed higer than flat\n",
    "    greater = np.count_nonzero(greater,axis=1).reshape((1,-1))\n",
    "    lesser = diffs<=-flat # all the times the price fell lower than fat\n",
    "    lesser = np.count_nonzero(lesser,axis=1).reshape((1,-1))\n",
    "#     return greater,lesser\n",
    "#     print(greater)\n",
    "    greater = greater.reshape(1,-1)\n",
    "    changeToBuy = np.any(greater > lesser & np.greater(greater,atleast*lookahead),axis=0) # make sure more rises than falls and atleast half rises\n",
    "    changeToSell = np.any(lesser > greater & np.greater(lesser,atleast*lookahead),axis=0)      # make sure more falls than rises and atleast half rises\n",
    "    changeToHold = ~changeToBuy & ~changeToSell\n",
    "    resLagged = resLagged.drop(colsLookAhead,1)\n",
    "    resLagged.loc[changeToSell,str(last+1)] = -1 # Set sell to -1\n",
    "    resLagged.loc[changeToBuy,str(last+1)] = 1 # Set buy to 1\n",
    "    resLagged.loc[changeToHold,str(last+1)] = 0 # Set to 0\n",
    "    return resLagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nifty. Reading and Cleaning\n",
    "fut = pd.read_csv(\"Nifty50FUT.csv\")\n",
    "fut['Price']= fut['Price'].str.replace(\",\",\"\").astype(np.double)\n",
    "fut['Open']= fut['Open'].str.replace(\",\",\"\").astype(np.double)\n",
    "fut['High']= fut['High'].str.replace(\",\",\"\").astype(np.double)\n",
    "fut['Low']= fut['Low'].str.replace(\",\",\"\").astype(np.double)\n",
    "fut['Vol.']= fut['Vol.'].str.replace(\",\",\"\").str.replace(\"M\",\"e6\").str.replace(\"-\",\"0\").str.replace(\"K\",\"e3\").astype(np.double)\n",
    "fut = fut[::-1]\n",
    "fut.reset_index(inplace=True, drop = True)\n",
    "\n",
    "nifty = pd.read_csv(\"Nifty.csv\")\n",
    "nifty = nifty[::-1]\n",
    "nifty.reset_index(inplace=True, drop = True)\n",
    "nifty['Price']= nifty['Price'].str.replace(\",\",\"\").astype(np.double)\n",
    "nifty['Open']= nifty['Open'].str.replace(\",\",\"\").astype(np.double)\n",
    "nifty['High']= nifty['High'].str.replace(\",\",\"\").astype(np.double)\n",
    "nifty['Low']= nifty['Low'].str.replace(\",\",\"\").astype(np.double)\n",
    "nifty['Vol.']= nifty['Vol.'].str.replace(\",\",\"\").str.replace(\"M\",\"e6\").str.replace(\"-\",\"0\").str.replace(\"K\",\"e3\").astype(np.double)\n",
    "\n",
    "\n",
    "niftyDrop = np.setdiff1d(fut['Date'].values,nifty['Date'].values)\n",
    "futDrop = np.setdiff1d(nifty['Date'].values,fut['Date'].values)\n",
    "nifty = nifty[~nifty.Date.isin(futDrop)]\n",
    "fut = fut[~fut.Date.isin(niftyDrop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nifty Base\n",
    "volNifty = nifty['Vol.'].diff().dropna()\n",
    "openNifty = nifty['Open'].diff().dropna()\n",
    "highNifty = nifty['High'].diff().dropna()\n",
    "lowNifty = nifty['Low'].diff().dropna()\n",
    "dataNifty = nifty['Price'].diff().dropna()\n",
    "\n",
    "# Nifty Futs\n",
    "volFut = fut['Vol.'].diff().dropna()\n",
    "openFut = fut['Open'].diff().dropna()\n",
    "highFut = fut['High'].diff().dropna()\n",
    "lowFut = fut['Low'].diff().dropna()\n",
    "dataFut = fut['Price'].diff().dropna()\n",
    "#Future Premium\n",
    "prems = dataFut.values - dataNifty.values\n",
    "prems = pd.Series(prems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag=14\n",
    "lookahead = 1\n",
    "flat = 1\n",
    "# First N predicts N+1th. Creating the 1st N series\n",
    "closeNifty = timeseriesLagged(dataNifty,lag + lookahead-1)\n",
    "# These are correlated with closeNifty, so we will ignore them for now\n",
    "# openNifty = timeseriesLagged(openNifty,lag + lookahead-1).drop(str(lag+1),axis=1)\n",
    "# highNifty = timeseriesLagged(highNifty,lag + lookahead-1).drop(str(lag+1),axis=1)\n",
    "# lowNifty = timeseriesLagged(lowNifty,lag + lookahead-1).drop(str(lag+1),axis=1)\n",
    "\n",
    "volNifty = timeseriesLagged(volNifty,lag + lookahead-1).drop(str(lag+1),axis=1)\n",
    "volNifty = skp.scale(volNifty,axis=1)\n",
    "\n",
    "# First N predicts N+1th. Creating the 1st N series\n",
    "closeFut = timeseriesLagged(dataFut,lag + lookahead-1).drop(str(lag+1),axis=1)\n",
    "closeFut = skp.scale(closeFut,axis=1)\n",
    "\n",
    "# These are correlated with closeNifty, so we will ignore them for now\n",
    "# openNifty = timeseriesLagged(openNifty,lag + lookahead-1).drop(str(lag+1),axis=1)\n",
    "# highNifty = timeseriesLagged(highNifty,lag + lookahead-1).drop(str(lag+1),axis=1)\n",
    "# lowNifty = timeseriesLagged(lowNifty,lag + lookahead-1).drop(str(lag+1),axis=1)\n",
    "volFut = timeseriesLagged(volFut,lag + lookahead-1).drop(str(lag+1),axis=1)\n",
    "volFut = skp.scale(volFut,axis=1)\n",
    "\n",
    "prems = timeseriesLagged(prems,lag + lookahead-1).drop(str(lag+1),axis=1)\n",
    "prems = skp.scale(prems,axis=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "closeNifty.loc[closeNifty[str(lag+1)] > flat,str(lag+1)] = 1\n",
    "closeNifty.loc[closeNifty[str(lag+1)] < flat,str(lag+1)] = -1\n",
    "closeNifty.loc[closeNifty[str(lag+1)] == flat,str(lag+1)] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "buySeriesLabs = closeNifty[str(lag+1)] # labels\n",
    "buySeriesFeats = closeNifty.drop(str(lag+1),axis=1) #features\n",
    "buySeriesFeats = buySeriesFeats.values\n",
    "buySeriesFeats = skp.scale(buySeriesFeats,axis=1)\n",
    "\n",
    "buySeries = np.zeros((len(buySeriesFeats),buySeriesFeats.shape[-1],5))\n",
    "buySeries[:,:,0] = buySeriesFeats\n",
    "buySeries[:,:,1] = volFut\n",
    "buySeries[:,:,2] = prems\n",
    "buySeries[:,:,3] = closeFut\n",
    "buySeries[:,:,4] = volNifty\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np_utils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-128-ca041819b9fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0myOrig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mtrainPercent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.9\u001b[0m \u001b[1;31m# majority of data used for training\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mtestPercent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.9\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np_utils' is not defined"
     ]
    }
   ],
   "source": [
    "# x,y = shuffle(buySeries,buySeriesLabs)\n",
    "x,y = buySeries,buySeriesLabs\n",
    "tot = len(x)\n",
    "y = y.values\n",
    "yOrig = np.copy(y)\n",
    "y = np_utils.to_categorical(y,3)\n",
    "trainPercent = 0.9 # majority of data used for training\n",
    "testPercent = 0.9 # \n",
    "valPercent = 1.00  #\n",
    "\n",
    "# Test Train Val Split\n",
    "\n",
    "xTrain = x[0:int(trainPercent*tot),:,:]\n",
    "yTrain = y[0:int(trainPercent*tot)]\n",
    "\n",
    "xTest = x[int(trainPercent*tot): int(testPercent*tot),:,:]\n",
    "yTest = y[int(trainPercent*tot): int(testPercent*tot)]\n",
    "\n",
    "xVal = x[int(testPercent*tot):,:,:]\n",
    "yVal = y[int(testPercent*tot):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
